{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fonnesbeck/vi_pydata_virginia_2025/blob/master/notebooks/Intro_Variational_Inference.ipynb)\n",
    "\n",
    "# Introduction to Variational Bayesian Methods\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Bayesian analysis, the most common strategy for computing posterior quantities is through Markov Chain Monte Carlo (MCMC). Despite recent advances in efficient sampling, MCMC methods still remain computationally intensive for very large datasets. A more scalable alternative to sampling is Variational Inference (VI), which re-frames the problem of computing the posterior distribution as a minimization of the distance between the true posterior and a member of some approximating family. \n",
    "\n",
    "In this section, we provide a basic overview of the VI framework as well as practical examples of its implementation using methods implemented in PyMC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of alternatives to evaluating complex posterior distributions without using an MCMC algorithm:\n",
    "\n",
    "1. Divide and Conquer approaches: See [this paper](https://arxiv.org/abs/1311.4780) or [this paper](https://arxiv.org/abs/1508.05880) for more details\n",
    "\n",
    "2. Build an approximation to the posterior $p(\\theta|X)$ using some other distribution $q(\\theta)$\n",
    "\n",
    "We will focus on the latter option, and try to use a simple distribution to approximate a complex one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributional Approximations\n",
    "\n",
    "One approach is to use a distributional approximation, such as the **Laplace (normal) approximation**. In that scenario, we construct a Taylor series of the posterior and threw away the terms of higher than quadratic order. \n",
    "\n",
    "**Variational inference** is another distribitional approximation method. Here, rather than a Taylor series approximation, we choose some class of approximating distributions, and choose the member of that class which is **closest to the posterior**.\n",
    "\n",
    "Thus, we shift from a stochastic sampling approach to approximation to a deterministic approximation that places bounds on the density of interest, then uses opimization to choose from that bounded set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Approximating a Student's-t with a Gaussian \n",
    "Let's approximate a Student's t distribution with $\\nu =3$  with a Gaussian distribution of some mean and variance.\n",
    "\n",
    " \n",
    "> **Student's-t distribution**\n",
    "> \n",
    "> The Student's-t distribution is symmetric and bell-shaped, like the normal distribution, but has heavier tails, meaning it is more prone to producing values that fall far from its mean. The parameter $\\nu$ (nu) controls the overdispersion of the distribution - as $\\nu$ increases, the distribution approaches a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 3\n",
    "logp = sp.stats.t(nu).logpdf\n",
    "logq_norm = sp.stats.norm(0, 1).logpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linspace(-5.0, 5.0, 1000)\n",
    "plt.plot(theta, np.exp(logp(theta)), label='p(theta)')\n",
    "plt.plot(theta, np.exp(logq_norm(theta)), label='q(theta)')\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we measure the distance between two distributions? One naive approach would be to build a set of test points and minimize the mean squared error (MSE) between the $\\log p(z)$ and $\\log q(z)$. \n",
    "\n",
    "$$\n",
    "{\\hat \\phi} = \\underset{\\phi}{{\\rm arg\\,min}} \\frac{\\sum_{i} q(\\theta_{i};\\phi)\\left[\\log q(\\theta_{i};\\phi) - \\log p(\\theta_{i})\\right]^{2}}{\\sum_{i} q(\\theta_{i};\\phi)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the approximation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's weight points that have more probability in the approximation $q(z)$, the idea being that points near the bulk of  $q(\\theta)$ are more important to get right. \n",
    "\n",
    "How do we pick $\\theta$? Well, let's use the known distribution of  $q(\\theta;\\phi)$  at each step of the optimization to select a grid of points which sample the regions of highest probability density. Then we will optimize the objective function that we defined in terms of MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logq(theta, mu, lnsigma):\n",
    "    # log-Gaussian parameterized by mean and log(sigma)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    return sp.stats.norm(mu, sigma).logpdf(theta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can specify an objective function, and fit the normal distribition using `scipy.optimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_vi(logp, n, mu_start, lnsigma_start, atol=1e-6):\n",
    "    \"\"\"use an optimizer for simple 1D VI\"\"\"\n",
    "    phi_start = np.array([mu_start, lnsigma_start])\n",
    "    \n",
    "    # Objective function. Computes sum above on a grid.\n",
    "    def obj(phi):\n",
    "        _sigma = np.exp(phi[1])  # get sigma\n",
    "        \n",
    "        # This is the grid, factor of 10 is an arbitrary choice.\n",
    "        z = np.linspace(phi[0] - 10.0*_sigma , phi[0] + 10.0*_sigma, n)\n",
    "\n",
    "        # Build weights and differences.\n",
    "        logqz = logq(z, phi[0], phi[1])\n",
    "        w = np.exp(logqz)\n",
    "        diff = logqz - logp(z)\n",
    "        return np.sum(diff * diff * w) / np.sum(w)\n",
    "\n",
    "    # Run the optimizer.\n",
    "    opts = {'disp': True, 'maxiter': 5000, 'maxfev': 5000,\n",
    "            'fatol': atol, 'xatol': 1e-8}\n",
    "    phi_hat = sp.optimize.minimize(obj, phi_start,\n",
    "                                      method='Nelder-Mead',\n",
    "                                      options=opts)\n",
    "    print(phi_hat)\n",
    "    return phi_hat['x'], phi_hat\n",
    "\n",
    "phi_hat, res = regression_vi(logp, 100, 100.0, -100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptheta = np.exp(logp(theta))\n",
    "qtheta_mse = np.exp(logq(theta, phi_hat[0], phi_hat[1]))\n",
    "\n",
    "plt.plot(theta, ptheta, label='p(theta)')\n",
    "plt.plot(theta, qtheta_mse, label='q(theta)')\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('PDF')\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE is not an effective criterion for comparing two arbitrary distributions (its only optimal when the approximation error is normally distributed). Instead, we can adopt a more robust information-theoretic measure, such as the **Kullback-Leibler divergence**, which estimates the information distance between two densities.\n",
    "\n",
    "> **Kullback-Leibler Divergence**\n",
    ">\n",
    "> The Kullback-Leibler (KL) divergence is a measure of how one probability distribution differs from another. It represents the relative entropy between two distributions and is always non-negative, being zero only when the distributions are identical. While not a true metric (it's asymmetric), KL divergence is widely used in machine learning for comparing probability distributions.\n",
    "\n",
    "The objective is to minimize the KL divergence between the approximating distribution and the truth:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "D_{\\rm KL}\\big(Q||P\\big) &= \\int q(\\theta) \\log\\frac{q(\\theta)}{p(\\theta)}d\\theta \\\\[1.5em]\n",
    "&= \\underbrace{\\int q(\\theta)\\log q(\\theta)d\\theta}_{\\text{entropy of }q(\\theta)} - \\underbrace{\\int q(\\theta)\\log p(\\theta)d\\theta}_{\\text{expected log likelihood under }q(\\theta)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_vi(logp, n, mu_start, lnsigma_start):\n",
    "    \"\"\"vi with KL divergence\"\"\"\n",
    "    phi_start = np.array([mu_start, lnsigma_start])\n",
    "    \n",
    "    # Objective function. Computes the KL div of q and p.\n",
    "    def obj(phi):\n",
    "        # This term is -\\int q*log(q).\n",
    "        # Also known as the differential entropy.\n",
    "        # For a Gaussian, it can be computed exactly. \n",
    "        # See wikipedia or something.\n",
    "        entropy = phi[1] + 0.5*np.log(2.0 * np.pi) + 0.5 ## \n",
    "        \n",
    "        # now we need to evaluate the second integral in the KL divergence, let's numerically approximate it with a sum\n",
    "        # This is the grid, factor of 20 is a random choice.\n",
    "        _sigma = np.exp(phi[1])  # get sigma        \n",
    "        θ = np.linspace(phi[0] - 20.0*_sigma , phi[0] + 20.0*_sigma, n) #number of grid points \n",
    "        dθ = θ[1] - θ[0]  # factor needed for numerical integral\n",
    "        \n",
    "        # This term is \\int q*log(p)\n",
    "        logqθ = logq(θ, phi[0], phi[1]) #just evaluate the variational density at each z on the grid and \n",
    "                                        # at the current value of phi\n",
    "        qθ = np.exp(logqθ) # back transform\n",
    "        return -entropy - np.sum(qθ * logp(θ) * dθ) #KL divergence for this phi\n",
    "    \n",
    "    # Pass this objective function to a scipy optimizer\n",
    "    phi_hat = sp.optimize.minimize(obj, phi_start,\n",
    "                                      method='Nelder-Mead',\n",
    "                                      options={'disp': True})\n",
    "    print(phi_hat)\n",
    "    return phi_hat['x'], phi_hat\n",
    "\n",
    "phi_hat, res = kl_vi(logp, 10000, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linspace(-5.0, 5.0, 1000)\n",
    "ptheta = np.exp(logp(theta))\n",
    "qtheta_vi = np.exp(logq(theta, phi_hat[0], phi_hat[1]))\n",
    "\n",
    "plt.plot(theta, ptheta, label='p(theta)')\n",
    "plt.plot(theta, qtheta_vi, label='q(theta)')\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('PDF')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the same result as MSE gave us. So, this is as close as we can get with a Gaussian approximation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Manual VI\n",
    "\n",
    "To get a better sense of what is going on here, use the widget below to approximate various target distributions using just a Gaussian variational approximation. Manipulate the parameters of the Gaussian and try to get the best fit for the target distribution, using the KL divergence as the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_visualization import JupyterVariationalInferenceViz\n",
    "\n",
    "viz = JupyterVariationalInferenceViz()\n",
    "viz.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at a more difficult pdf to approximate:\n",
    "$$\n",
    " \\log p(\\theta) = 10^{3}\\log \\theta + \\log(1-\\theta) - c\n",
    "$$\n",
    "\n",
    "where the constant $c \\sim Beta(10^3+1, 2)$.\n",
    "\n",
    "This is an unusual distribution, constrained to the interval $[0,1]$ and with a very sharp peak near 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logp_hard(theta, a=1e3, b=1):\n",
    "    val = np.zeros_like(theta)\n",
    "    msk = (theta >= 1.0) | (theta <= 0.0)\n",
    "    val[msk] = -np.inf\n",
    "    if np.any(~msk):\n",
    "        val[~msk] = a * np.log(theta) + b * np.log(1.0 - theta) - sp.special.betaln(a + 1.0, b + 1.0)\n",
    "    return val\n",
    "\n",
    "theta = np.linspace(0.98, 0.999999, 100000)\n",
    "ptheta = np.exp(logp_hard(theta))\n",
    "plt.plot(theta, ptheta)\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('PDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, let's visualise this with the logit transformation of $\\theta$, which maps $[0,1] \\to R$:\n",
    "\n",
    "$$T(\\theta)=\\zeta = {\\rm logit}(\\theta) = \\log\\left(\\frac{\\theta}{1-\\theta}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linspace(0.5, 0.999999, 100000)\n",
    "ptheta = np.exp(logp_hard(theta))\n",
    "dtheta_dlogittheta = theta * (1.0 - theta)\n",
    "\n",
    "plt.plot(sp.special.logit(theta), ptheta * dtheta_dlogittheta, label='p(logit(theta))')\n",
    "plt.xlabel('logit(theta)')\n",
    "plt.ylabel('PDF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive approach here would be to proceed as above, fitting a rescaled Gaussian to match the support of $\\theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logq_unit(theta, mu, lnsigma):\n",
    "    \"\"\"log of Gaussian parameterized by mean and log(sigma)\n",
    "    has unit integral over 0,1 \n",
    "    and value zero outside of 0,1\n",
    "    \"\"\"\n",
    "    val = np.zeros_like(theta)\n",
    "    msk = (theta >= 1.0) | (theta <= 0.0)\n",
    "    val[msk] = -np.inf\n",
    "    if np.any(~msk):\n",
    "        sigma = np.exp(lnsigma)\n",
    "        a, b = (0.0 - mu) / sigma, (1.0 - mu) / sigma\n",
    "        val[~msk] = sp.stats.truncnorm.logpdf(theta[~msk], a=a, b=b, loc=mu, scale=sigma)\n",
    "    \n",
    "    return val\n",
    "\n",
    "def kl_vi_unit(logp, n, mu_start, lnsigma_start, eps=1e-8):\n",
    "    \"\"\"vi with KL divergence over unit integral\"\"\"\n",
    "    phi_start = np.array([mu_start, lnsigma_start])\n",
    "    \n",
    "    # Objective function. Computes the KL div of q and p.\n",
    "    def obj(phi):\n",
    "        # This term is -\\int q*log(q).\n",
    "        sigma = np.exp(phi[1])\n",
    "        a, b = (0.0 - phi[0]) / sigma, (1.0 - phi[0]) / sigma\n",
    "        entropy = sp.stats.truncnorm.entropy(a=a, b=b, loc=phi[0], scale=sigma)\n",
    "\n",
    "        # This is the grid, factor of 20 is a random choice.\n",
    "        theta = np.linspace(eps, 1.0 - eps, n)\n",
    "        dtheta= theta[1] - theta[0]  # factor needed for numerical integral\n",
    "        \n",
    "        # This term is \\int q*log(p)\n",
    "        logqtheta = logq_unit(theta, phi[0], phi[1])\n",
    "        qtheta = np.exp(logqtheta)\n",
    "\n",
    "        return -entropy - np.sum(qtheta * logp(theta) * dtheta)\n",
    "\n",
    "    # Run the optimizer.\n",
    "    phi_hat = sp.optimize.minimize(obj, phi_start,\n",
    "                                      method='Nelder-Mead',\n",
    "                                      options={'disp': True, 'maxfev': 10000})\n",
    "    print(phi_hat)\n",
    "    return phi_hat['x'], phi_hat\n",
    "\n",
    "phi_hat, res = kl_vi_unit(logp_hard, 10000, 0.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtheta = np.exp(logq_unit(theta, phi_hat[0], phi_hat[1]))\n",
    "\n",
    "plt.plot(sp.special.logit(theta), ptheta * dtheta_dlogittheta, label='p(logit(theta))')\n",
    "plt.plot(sp.special.logit(theta), qtheta * dtheta_dlogittheta, label='q(logit(theta))')\n",
    "plt.xlabel('logit(theta)')\n",
    "plt.ylabel('PDF')\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a little weird and rescaling a gaussian to squeeze into the support of $\\theta$ is not really a good solution if your parameters all have different supports.\n",
    "\n",
    "Instead, let's do the reverse and transform the **parameter space** to that of a Gaussian. Again, we can use the logit function.\n",
    " \n",
    "$$\n",
    "{\\rm logit}^{-1}(\\zeta) = {\\rm sigmoid}(\\zeta) = \\frac{1}{1 + \\exp\\left(-\\zeta\\right)}\\\\\n",
    "\\frac{d{\\rm sigmoid}(\\zeta)}{d\\zeta} = {\\rm sigmoid}(\\zeta) \\left[1 - {\\rm sigmoid}(\\zeta)\\right]\\\\\n",
    "$$\n",
    "and then our pdf in terms of the transformed parameter is given by\n",
    "$$\n",
    "\\begin{align*}\n",
    " \\log p_{\\zeta}(\\zeta) &= \\log p({\\rm sigmoid}(\\zeta)) + \\log\\left|\\frac{d{\\rm sigmoid}(\\zeta)}{d\\zeta}\\right|\\\\\n",
    "&= \\log p({\\rm sigmoid}(\\zeta)) + \\log {\\rm sigmoid}(\\zeta) + \\log(1-{\\rm sigmoid}(\\zeta))\\ .\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logp_easy(logitθ, a=1e3, b=1):\n",
    "    logabsjac = -1.0 * (np.log(1.0 + np.exp(-logitθ)) + np.log(1.0 + np.exp(logitθ)))\n",
    "    return (-a * np.log(1.0 + np.exp(-logitθ)) - b * np.log(1.0 + np.exp(logitθ)) + \n",
    "            logabsjac - \n",
    "            sp.special.betaln(a + 1.0, b + 1.0))\n",
    "\n",
    "phi_hat, res = kl_vi(logp_easy, 10000, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_theta = np.linspace(0.0, 14.0, 100000)\n",
    "plogit_theta = np.exp(logp_easy(logit_theta))\n",
    "qlogit_theta = np.exp(logq(logit_theta, phi_hat[0], phi_hat[1]))\n",
    "\n",
    "plt.plot(logit_theta, plogit_theta, label='p(logit(theta))')\n",
    "plt.plot(logit_theta, qlogit_theta, label='q(logit(theta))')\n",
    "plt.xlabel('logit(z)')\n",
    "plt.ylabel('PDF')\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly re-casting $\\theta$ to have the same support as a Gaussian makes for nice and easy minimization and fits much better than the other way around. \n",
    "\n",
    "We will use this as a general strategy for automating variational inference.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating an unknown posterior distribution\n",
    "\n",
    "One obvious limitation of each of the methods we have seen so far is that they all assume that we know the form of the posterior distribution. This is rarely the case in practice.\n",
    "\n",
    "**What can we do if we don't know the form of the posterior?**\n",
    "\n",
    "Let's revisit the KL divergence and see what is available to us:\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi^*=\\arg\\min_{\\phi\\in\\Phi}D_{\\rm KL}(q(\\theta; \\phi) || p(\\theta|X))\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The KL divergence is given by\n",
    "\n",
    "\\begin{align*}\n",
    "D_{\\rm KL}\\big(Q||P\\big) &= \\int q(\\theta) \\log\\frac{q(\\theta)}{p(\\theta|x)}d\\theta\n",
    "\\end{align*}\n",
    "\n",
    "This is the definition of the KL divergence between our approximating distribution $q(\\theta)$ and the true posterior $p(\\theta|x)$.\n",
    "\n",
    "We can rewrite this as an expectation with respect to $q$:\n",
    "\n",
    "\\begin{align*}\n",
    "D_{\\rm KL}\\big(Q||P\\big) &= E_q\\left[\\log\\frac{q(\\theta)}{p(\\theta|x)}\\right]\n",
    "\\end{align*}\n",
    "\n",
    "Using the properties of logarithms, we can split this into two separate expectations:\n",
    "\n",
    "\\begin{align*}\n",
    "D_{\\rm KL}\\big(Q||P\\big) &= E_q[\\log q(\\theta)] - E_q[\\log p(\\theta|x)]\n",
    "\\end{align*}\n",
    "\n",
    "Then, applying the definition of conditional probability to the second term, we get:\n",
    "\n",
    "\\begin{align*}\n",
    "D_{\\rm KL}\\big(Q||P\\big) &= E_q[\\log q(\\theta)] - E_q[\\log \\frac{p(\\theta,x)}{p(x)}] \n",
    "\\end{align*}\n",
    "\n",
    "Finally, let's rearrange the terms:\n",
    "\n",
    "\\begin{align*}\n",
    "D_{\\rm KL}\\big(Q||P\\big) &= E_q[\\log q(\\theta)] - E_q[\\log p(\\theta,x)] + E_q[\\log p(x)] \\\\\n",
    "&= E_q[\\log q(\\theta)] - E_q[\\log p(\\theta,x)] + \\log p(x)\n",
    "\\end{align*}\n",
    "\n",
    "The last step follows because $\\log p(x)$ is constant with respect to $\\theta$, so $E_q[\\log p(x)] = \\log p(x)$.\n",
    "\n",
    "This gives us a quantity called the **Evidence Lower Bound (ELBO)** which is defined as $ELBO = E_q[\\log p(\\theta,x)] - E_q[\\log q(\\theta)]$, so:\n",
    "\n",
    "\\begin{align*}\n",
    "D_{\\rm KL}\\big(Q||P\\big) &= -ELBO + \\log p(x)\n",
    "\\end{align*}\n",
    "\n",
    "Notice that the KL divergence is given by the sum of the ELBO and Model Evidence. To see why, let's revisit the model evidence. \n",
    "\n",
    "\\begin{align*}\n",
    "\\log p(x)&=&\\log\\int p(x,\\theta)d\\theta\\\\\n",
    "&=&\\log\\int p(x,\\theta)\\frac{q(\\theta)}{q(\\theta)}d\\theta\\\\\n",
    "&=&\\log(E_{q}\\left[\\frac{p(x,\\theta)}{q(\\theta)}\\right])\\\\\n",
    "&\\geq& E_q[\\log p(x,\\theta)]-E_q[\\log q(\\theta)].\n",
    "\\end{align*}\n",
    "\n",
    "This is due to the fact that logarithms are strictly concave, allowing us to invoke [**Jensen's inequality**](http://mathworld.wolfram.com/JensensInequality.html):\n",
    "\n",
    "> Let $f$ be a convex function (*i.e.* $f^{\\prime\\prime} \\ge 0$) of a random variable X. Then:\n",
    "> $f(E[X]) \\ge E[f(X)]$\n",
    ">\n",
    "> And when $f$ is *strictly* convex, then:\n",
    "> $$E[f(X)] = f(E[X]) \\iff X = E[X]$$\n",
    "> with probability 1.\n",
    "\n",
    "What this implies for a computational solution is that minimizing the KL divergence is accomplished by maximizing the evidence lower bound.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Automatic Differentiation Variational Inference: A Tale of Two Transformations\n",
    "\n",
    "[Kucukelbir et. al. 2015](https://arxiv.org/abs/1603.00788) developed Automatic Differentiation Variational Inference (ADVI) to make variational inference more automated and broadly applicable. The key insight is to transform the inference problem through two clever changes of variables:\n",
    "\n",
    "1. First, we start with our probabilistic model $p(x,\\theta)$ where $\\theta$ are the model parameters that may have constraints (e.g. must be positive). \n",
    "\n",
    "2. The first transformation $T$ maps the constrained parameters $\\theta$ to unconstrained real-valued variables $\\zeta = T(\\theta)$. For example:\n",
    "   - Positive parameters are log-transformed\n",
    "   - Probability simplexes use stick-breaking transforms\n",
    "   - Bounded intervals use sigmoid transforms\n",
    "   \n",
    "   This gives us a new joint distribution $p(x,\\zeta)$ where all variables live in $\\mathbb{R}^K$.\n",
    "\n",
    "3. We can now use a simple mean-field Gaussian variational family $q(\\zeta;\\phi)=N(\\zeta|\\mu,\\text{diag}(\\omega^2))$ where $\\phi=(\\mu,\\omega)$ are the variational parameters we need to optimize.\n",
    "\n",
    "4. The second transformation $S_{\\mu,\\omega}$ maps a standard normal $\\eta \\sim N(0,I)$ to our variational distribution via $\\zeta = S_{\\mu,\\omega}(\\eta) = \\mu + \\omega \\odot \\eta$. This standardization makes Monte Carlo estimation of the ELBO much more efficient.\n",
    "\n",
    "5. Finally, we can optimize the variational parameters $\\phi$ using stochastic gradient ascent on the ELBO:\n",
    "\n",
    "   $$\\phi^* = \\arg\\max_{\\phi} \\text{ELBO}(\\phi)$$\n",
    "\n",
    "The figure below illustrates these transformations:\n",
    "- (a) shows the original constrained parameter space\n",
    "- (b) shows the unconstrained space after applying $T$ \n",
    "- (c) shows the standardized space where we perform efficient Monte Carlo integration\n",
    "\n",
    "The beauty of ADVI is that these transformations happen automatically - the user only needs to specify their probabilistic model and ADVI handles the rest!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/advi.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get a feel for how this happens "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we're first going to transform all of our parameters to have the same support in $R^k$. We next need to optimize the KL divergence on the transformed space (like in the sigmoid transformation above). \n",
    "\n",
    "To accomplish this, we need to optimize the ELBO for the transformed objective. Our objective function for the transformed variables is now given by the ELBO of the transformation:\n",
    "\n",
    "$$\n",
    "ELBO(\\phi) = \\underbrace{E_{q(\\zeta;\\phi)}\\left[\\log p(x,T^{-1}(\\zeta))+\\log|\\det J_{T^{-1}}(\\zeta)|\\right]}_{\\text{Expected log joint density + Jacobian correction}} - \\underbrace{E_q[\\log q(\\zeta;\\phi)]}_{\\text{Entropy of }q}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notation is starting to get a litle hairy, so let's return to basics. Remember, the first expectation is just an expectation over a joint likelihood in terms of the approximating variational distribution (hence the correction term).  \n",
    "\n",
    "This is appoximated by drawing samples from the variational distribution and computing the mean of the log joint density.\n",
    "\n",
    "$$\n",
    "\\int q(z)\\log p(x,T^{-1}(\\zeta))|\\det J_{T^{-1}}(\\zeta)| dz \\approx \\frac{1}{n}\\sum_i \\log p(x|\\zeta_{i})p(\\zeta_{i})\n",
    "$$\n",
    "\n",
    "Problem is, we can't differentiate this MC integration with respect to the variational parameters (since they parameterize the distribution from which we draw $\\zeta_i$). So we need to transform one more time so that the expectation is in terms of a standard normal (this is called **elliptic standardization**), and them perform MC integration with a draw from a standard normal. \n",
    "\n",
    "$$\\begin{align}\n",
    "\\int q(\\zeta) \\log p(x|\\zeta)p(\\zeta) d\\zeta &= \\int N(\\zeta) \\log p(x|\\zeta\\sigma+\\mu)p(\\zeta\\sigma+\\mu) dz \\\\\n",
    "&\\approx \\frac{1}{n}\\sum_i \\log p(x|\\zeta_{i}\\sigma+\\mu)p(\\zeta_{i}\\sigma+\\mu)\\ .\n",
    "\\end{align}$$\n",
    "\n",
    "Now, since this integral is explicitly in terms of the variational parameters, we can optimize our objective. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Above is something we can take derivatives of using a computational backend. We'll use PyMC in a moment. But let's return to our weird pdf.\n",
    "\n",
    "We can now implement a really crude version of advi on our weird pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dlogp_easy_dzeta(zeta):\n",
    "    theta = sp.special.expit(zeta)\n",
    "    return (1e3 + 1.0) * (1.0 - theta) - 2 * theta\n",
    "\n",
    "def kl_vi_with_sgd(dlogp, mu, lnsigma, rng, n_iter=100000, n_draw=1, eta=5e-4, eta_decay=5e-5):\n",
    "    for i in range(n_iter):\n",
    "        # Draw the points and convert back to draws from the variational approximation.\n",
    "        zeta_standard = rng.normal(size=n_draw)\n",
    "        sigma = np.exp(lnsigma)\n",
    "        zeta = zeta_standard*sigma + mu\n",
    "        \n",
    "        # Compute the derivs.\n",
    "        dkl_dmu = -np.mean(dlogp(zeta))\n",
    "        dkl_dlnsigma = -np.mean(dlogp(zeta) * zeta_standard * sigma) - 1\n",
    "        \n",
    "        # Now do SGD with the KL divergence.\n",
    "        lnsigma -= dkl_dlnsigma * eta\n",
    "        mu -= dkl_dmu * eta\n",
    "        \n",
    "        # Decay the learning rate.\n",
    "        eta *= 1.0 - eta_decay\n",
    "        \n",
    "        if not (i % (n_iter // 25)):\n",
    "            print(\"iter, mu, lnsigma: % 7d|% 10.4e|% 10.4e\" % \n",
    "                  (i, mu, lnsigma))\n",
    "        \n",
    "    return np.array([mu, lnsigma])\n",
    "\n",
    "rng = np.random.RandomState(seed=5678)\n",
    "phi_hat = kl_vi_with_sgd(dlogp_easy_dzeta, 0.0, 0.0, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_theta = np.linspace(0.0, 14.0, 100000)\n",
    "plogit_theta = np.exp(logp_easy(logit_theta))\n",
    "qlogit_theta = np.exp(logq(logit_theta, phi_hat[0], phi_hat[1]))\n",
    "\n",
    "plt.plot(logit_theta, plogit_theta, label='p(logit(theta))')\n",
    "plt.plot(logit_theta, qlogit_theta, label='q(logit(theta))')\n",
    "plt.xlabel('logit(theta)')\n",
    "plt.ylabel('PDF')\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we certainly don't want to have to compute derivatives all by hand!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference in PyMC\n",
    "\n",
    "For variational inference specifically, PyMC implements a few algorithms including ADVI.\n",
    "\n",
    "This automation makes it much easier to apply variational inference to complex models compared to implementing everything manually like we did above.\n",
    "\n",
    "First, let's briefly cover how to specify a model in PyMC.\n",
    "\n",
    "### Introduction to PyMC\n",
    "\n",
    "<img src=\"images/PyMC.png\" width=\"50%\" />\n",
    "\n",
    "PyMC is a probabilistic programming library for Python that allows users to build and analyze Bayesian statistical models. It provides a flexible framework for specifying models using an intuitive syntax and conducting statistical inference using various state-of-the-art algorithms.\n",
    "\n",
    "PyMC's feature set helps to make Bayesian analysis as painless as possible. Here is a short list of some of its features:\n",
    "\n",
    "-   Fits Bayesian statistical models with Markov chain Monte Carlo, variational inference and\n",
    "    other algorithms.\n",
    "-   Includes a large suite of well-documented statistical distributions.\n",
    "-   Leverages `arviz` for convergence diagnostics, model checking methods and creating summaries including tables and plots.\n",
    "-   Extensible: easily incorporates custom step methods and unusual probability distributions.\n",
    "-   Non-parametric Bayesian methods, including Gaussian processes and Dirichlet processes, are supported.\n",
    "\n",
    "PyMC offers intuitive model specification that allows users to define complex statistical models using syntax that closely resembles mathematical notation. The library includes powerful sampling algorithms such as Hamiltonian Monte Carlo (HMC) and the No-U-Turn Sampler (NUTS) for efficient MCMC sampling. For larger datasets, PyMC provides variational inference as a scalable approximation method. The system automatically handles parameter constraints through appropriate transformations, and integrates with ArviZ for comprehensive model diagnostics and visualization.\n",
    "\n",
    "To get you started, let's see how we can use PyMC to construct a simple logistic regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123) \n",
    "\n",
    "N_samples = 100\n",
    "N_features = 2 # Keep it 2D like Figure 1\n",
    "\n",
    "# True coefficients (e.g., intercept and one slope)\n",
    "beta_true = np.array([-1.0, 2.0])\n",
    "\n",
    "# Generate features (e.g., one feature column + intercept column)\n",
    "X = np.random.randn(N_samples, N_features - 1)\n",
    "X_design = np.hstack([np.ones((N_samples, 1)), X]) # Add intercept column\n",
    "\n",
    "# Calculate probabilities\n",
    "linear_pred = X_design @ beta_true\n",
    "prob = 1 / (1 + np.exp(-linear_pred))\n",
    "\n",
    "# Generate binary outcomes\n",
    "y = stats.bernoulli.rvs(p=prob)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model')\n",
    "ax.scatter(X, y, alpha=0.5, label='sampled data')\n",
    "x_plot = np.linspace(X.min(), X.max(), 100)\n",
    "x_plot_design = np.hstack([np.ones((100, 1)), x_plot.reshape(-1, 1)])\n",
    "y_plot = 1 / (1 + np.exp(-x_plot_design @ beta_true))\n",
    "ax.plot(x_plot, y_plot, 'r-', label='true logistic curve', lw=2)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "\n",
    "Logistic regression is a statistical model that predicts binary outcomes by estimating the probability\n",
    "of an observation belonging to a particular class.\n",
    "\n",
    "The model takes the form:\n",
    "\n",
    "$$P(y=1|X) = \\sigma(\\mu + \\beta x) = \\frac{1}{1 + e^{-(\\mu + \\beta x)}}$$\n",
    "\n",
    "Where:\n",
    "- $\\theta = \\mu + \\beta x$ is the linear predictor\n",
    "- $\\sigma$ is the sigmoid function that maps any real value to $(0,1)$\n",
    "\n",
    "The decision boundary is defined by $\\mu + \\beta x = 0$ where $P(y=1|X) = 0.5$.\n",
    "\n",
    "In Bayesian inference, we place prior distributions on the parameters $\\beta$ and\n",
    "derive their posterior distribution given the observed data:\n",
    "\n",
    "$$p(\\mu,\\beta|X,y) \\propto p(y|X, \\mu, \\beta)p(\\mu)p(\\beta)$$\n",
    "\n",
    "### Implementing a PyMC Model\n",
    "\n",
    "At the model-specification stage (before the data are observed), $y$, $\\mu$, and $\\beta$ are all random variables. Bayesian \"random\" variables have not necessarily arisen from a physical random process. The Bayesian interpretation of probability is **epistemic**, meaning random variable $x$'s probability distribution $p(x)$ represents our knowledge and uncertainty about $x$'s value. Candidate values of $x$ for which $p(x)$ is high are relatively more probable, given what we know. \n",
    "\n",
    "We can generally divide the variables in a Bayesian model into two types: **stochastic** and **deterministic**. The only deterministic variable in this model is $\\theta$. If we knew the values of $\\theta$'s parents, we could compute the value of $\\theta$ exactly. A deterministic like $\\theta$ is defined by a mathematical function that returns its value given values for its parents. Deterministic variables are sometimes called the *systemic* part of the model. The nomenclature is a bit confusing, because these objects usually represent random variables; since the parents of $\\theta$ are random, $\\theta$ is random also.\n",
    "\n",
    "On the other hand, even if the values of the parents of variables `y` (before observing the data), $\\mu$ or $\\beta$ were known, we would still be uncertain of their values. These variables are stochastic, characterized by probability distributions that express how plausible their candidate values are, given values for their parents.\n",
    "\n",
    "Let's begin by defining the prior distributions for the model parameters. We will use a normal distribution for the intercept $\\mu$ and a normal distribution for the slope $\\beta$. The prior distributions represent our beliefs about the parameters before observing any data.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # Define priors\n",
    "    mu = pm.Normal('mu', 0, sigma=5)\n",
    "    beta = pm.Normal('beta', 0, sigma=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have done two things here. First, we have created a `Model` object; a `Model` is a Python object that encapsulates all of the variables that comprise our theoretical model, keeping them in a single container so that they may be used as a unit. After a `Model` is created, we can populate it with all of the model components that we specified when we wrote the model down. \n",
    "\n",
    "Notice that the `Model` above was declared using a `with` statement. This expression is used to define a Python idiom known as a **context manager**. Context managers, in general, are used to manage resources of some kind within a program. In this case, our resource is a `Model`, and we would like to add variables to it so that we can fit our statistical model. The key characteristic of the context manager is that the resources it manages are only defined within the indented block corresponding to the `with` statement. PyMC uses this idiom to automatically add defined variables to a model. Thus, any variable we define is automatically added to the `Model`, without having to explicitly add it.\n",
    "\n",
    "In fact, PyMC variables cannot be defined without a corresponding `Model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pm.Normal('mu', 0, sigma=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMC includes most of the common random variable **distributions** used for statistical modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.distributions.__all__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the variable `theta`, which is a deterministic variable that is defined as a function of the stochastic variables `mu` and `beta`, and the data `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    \n",
    "    theta = mu + beta * X.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unobserved_RVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `theta`, which is a determinsitic component of the model? In this model, `theta` has not been given a name and given a formal PyMC data structure. It is essentially an **intermediate calculation** in the model, implying that we are not interested in its value when it comes to summarizing the output from the model. Most PyMC objects have a name assigned; these names are used for storage and post-processing:\n",
    "\n",
    "-   as keys in output databases,\n",
    "-   as axis labels in plots of traces,\n",
    "-   as table labels in summary statistics.\n",
    "\n",
    "If we wish to include `theta` in our output, we need to make it a `Deterministic` object, and give it a name:\n",
    "\n",
    "```python\n",
    "theta = pm.Deterministic('theta', mu + beta * x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to define the **data likelihood**, or sampling distribution. In this case, our measured outcome the binary variable, `y`. This is a stochastic variable but unlike `mu` and `beta` we have *observed* its value. To express this, we set the argument `observed` to the observed outcome data. This tells PyMC that this distribution's value is fixed, and should not be changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    \n",
    "    likelihood = pm.Bernoulli('y', p=pm.math.invlogit(theta), observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMC's `sample` function will fit probability models (linked collections of variables) like ours using Markov chain Monte Carlo (MCMC) sampling. Unless we manually assign particular algorithms to variables in our model, PyMC will assign algorithms that it deems appropriate (it usually does a decent job of this):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "\n",
    "    trace = pm.sample(1000, tune=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the Markov chain of draws, conventionally called a \"trace\", from the model in an `InferenceData` object. This is from the `arviz` library that we have been using for plotting, and is an extension of the [xarray](https://xarray.pydata.org/en/stable/) data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the trace using the `plot_trace` function, one of many output processing and visualization functions from `arviz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "az.plot_trace(trace)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While MCMC is a great way to fit models, we are here to learn about variational inference.\n",
    "\n",
    "We invoke variational inference with the `fit` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    approx = pm.fit(n=20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogous to the `InferenceData` object, `approx` contains the variational approximation as an `Approximation` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the sequence of loss scores (-ELBO) which are stored in the `hist` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(approx.hist);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now sample from the approximation, to yield a trace in an `InferenceData` object, as we would from MCMC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_vi = approx.sample() \n",
    "az.plot_trace(trace_vi)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `trace_vi` acts exactly like a trace from mcmc. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean field variational inference\n",
    "\n",
    "By default, `fit` employs a mean field assumption regarding the model parameters. This assumes the variational distribution factors independently: \n",
    "\n",
    "$$q(\\theta_1, \\ldots, \\theta_n) = q(\\theta_1) \\cdots q(\\theta_n)$$\n",
    "\n",
    "We can generalize this to use a full-rank covariance matrix for our approximation, which carries an associated tradeoff in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    approx_fr = pm.fit(n=10_000, method='fullrank_advi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_fullrank = approx_fr.sample() \n",
    "az.plot_trace(trace_fullrank)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the full-rank approximation is more accurate, but at the cost of increased computation time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Mixture model\n",
    "\n",
    "Let's look at using VI to estimate a simple, but less straightforward model: a mixture model that features a bimodal posterior distribution. Mixture models can be specified easily in PyMC with the `Mixture` class, that accepts a set of densities and an associated set of weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([.2, .8])\n",
    "mu = np.array([-.3, .5])\n",
    "sd = np.array([.1, .1])\n",
    "\n",
    "with pm.Model() as mixture_model:\n",
    "    x = pm.NormalMixture('x', w=w, mu=mu, sigma=sd)\n",
    "    x2 = pm.Deterministic('x2', x ** 2)\n",
    "    sin_x = pm.Deterministic('sin_x', pm.math.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mixture_model:\n",
    "    mixture_trace = pm.sample(10_000, tune=5000, target_accept=0.9, cores=2, random_seed=(1, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(mixture_trace)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NUTS algorithm is easily able to sample from the distribution. Let's try to replicate the analysis with mean-field VI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mixture_model:\n",
    "    mean_field = pm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanfield_trace = mean_field.sample(500)\n",
    "az.plot_trace(meanfield_trace, var_names=['x']);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that ADVI has failed to approximate the multimodal distribution, since it uses a Gaussian distribution that has a single mode.\n",
    "\n",
    "## Checking convergence\n",
    "\n",
    "The `fit` function supports the use of \"callbacks\", which are functions that are passed as arguments to other functions, and executed at a specified time within that function. For example, the `CheckParametersConvergence` callback will monitor the model parameter trajectories, and stop the VI algoithm when convergence is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc.variational.callbacks import CheckParametersConvergence\n",
    "\n",
    "with mixture_model:\n",
    "    mean_field = pm.fit(callbacks=[CheckParametersConvergence()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_field.hist);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've reached convergence after a few thousand iterations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful callback allows users to track parameters directly during the fitting procedure. To do this we need to use the object-oriented (OO) API, which allows direct access to the approximation before inference is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with mixture_model:\n",
    "    advi = pm.ADVI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advi.approx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different approximations have different hyperparameters. In mean-field ADVI, we have $\\rho$ and $\\mu$ (inspired by [Bayes by BackProp](https://arxiv.org/abs/1505.05424))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advi.approx.shared_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are convenient shortcuts to relevant statistics associated with the approximation. This can be useful, for example, when specifying a mass matrix for NUTS sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advi.approx.mean.eval(), advi.approx.std.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can roll these statistics into the `Tracker` callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker = pm.callbacks.Tracker(\n",
    "    mean=advi.approx.mean.eval,  # callable that returns mean\n",
    "    std=advi.approx.std.eval  # callable that returns std\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calling `advi.fit` will record the mean and standard deviation of the approximation as it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx = advi.fit(15_000, callbacks=[tracker])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot both the evidence lower bound and parameter traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "mu_ax = fig.add_subplot(221)\n",
    "std_ax = fig.add_subplot(222)\n",
    "hist_ax = fig.add_subplot(212)\n",
    "mu_ax.plot(tracker['mean'])\n",
    "mu_ax.set_title('Mean track')\n",
    "std_ax.plot(tracker['std'])\n",
    "std_ax.set_title('Std track')\n",
    "hist_ax.plot(advi.hist)\n",
    "hist_ax.set_title('Negative ELBO track');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are convergence issues with the mean, and that lack of convergence does not seem to change the ELBO trajectory significantly. As we are using the OO API, we can run the approximation longer (using `refine`) until convergence is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advi.refine(10_000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "mu_ax = fig.add_subplot(221)\n",
    "std_ax = fig.add_subplot(222)\n",
    "hist_ax = fig.add_subplot(212)\n",
    "mu_ax.plot(tracker['mean'])\n",
    "mu_ax.set_title('Mean track')\n",
    "std_ax.plot(tracker['std'])\n",
    "std_ax.set_title('Std track')\n",
    "hist_ax.plot(advi.hist)\n",
    "hist_ax.set_title('Negative ELBO track');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still see evidence for lack of convergence, as the mean has devolved into a random walk. This could be the result of choosing a poor algorithm for inference. At any rate, it is unstable and can produce very different results even using different random seeds.\n",
    "\n",
    "Let's compare results with the NUTS output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Get the data\n",
    "nuts_samples = mixture_trace.posterior['x'].values.ravel()\n",
    "advi_samples = approx.sample(10_000).posterior['x'].values.ravel()\n",
    "\n",
    "# Create KDE for both distributions\n",
    "from scipy import stats\n",
    "x_range = np.linspace(min(np.min(nuts_samples), np.min(advi_samples)), \n",
    "                      max(np.max(nuts_samples), np.max(advi_samples)), 1000)\n",
    "nuts_kde = stats.gaussian_kde(nuts_samples)\n",
    "advi_kde = stats.gaussian_kde(advi_samples)\n",
    "\n",
    "# Create the plotly figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_range, y=nuts_kde(x_range), mode='lines', name='NUTS'))\n",
    "fig.add_trace(go.Scatter(x=x_range, y=advi_kde(x_range), mode='lines', name='ADVI'))\n",
    "fig.update_layout(xaxis_title='x', yaxis_title='Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So try as we might, ADVI is not able to capture the multimodality of the posterior distribution.\n",
    "\n",
    "While ADVI is the workhorse algorithm for variational inference in PyMC, there are other algorithms that can often do a better job. Let's look at a couple of them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stein Variational Gradient Descent (SVGD)\n",
    "\n",
    "SVGD is a general VI algorithm that iteratively shifts a set of particles to match a target posterior. This is done via a form of **functional gradient descent** that minimizes the KL divergence.\n",
    "\n",
    "1. Sample particles from prior distribution of parameters\n",
    "2. Formulate bijective (*i.e.* reversible) transformation of particles\n",
    "3. Iteratively apply transformation until convergence\n",
    "\n",
    "SVGD directly minimizes $KL(\\{x_i\\} || p)$ by iteratively moving points $\\{x_i\\}_{i=1}^n$ towards the target p by updates of form:\n",
    "\n",
    "$$x_i^{\\prime} \\leftarrow x_i + \\epsilon\\phi(x_i)$$\n",
    "\n",
    "where $\\phi$ is a *perturbation direction* chosen to optimally decrease the KL divergence:\n",
    "\n",
    "$$\\phi = \\text{argmax}_{\\phi}\\left\\{-\\frac{\\partial}{\\partial \\epsilon} KL(q_{[\\epsilon \\phi]} || p)|_{\\epsilon=0}\\right\\}$$\n",
    "\n",
    "where $q_{[\\epsilon \\phi]}$ is the density of $x^{\\prime}$ when the density of $x$ is $q$.\n",
    "\n",
    "The name of the procedure reflects the fact that this direction is related to the **Stein operator**:\n",
    "\n",
    "$$-\\frac{\\partial}{\\partial \\epsilon} KL(q_{[\\epsilon \\phi]} || p)|_{\\epsilon=0} = E_{x \\sim q}[\\mathcal{T}_p \\phi(x)]$$\n",
    "\n",
    "This animation shows the SVGD algorithm in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svgd_animated import create_svgd_demo\n",
    "\n",
    "fig = create_svgd_demo(target='banana', n_particles=50, n_frames=150)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyMC, we can invoke SVGD by passing the `method='svgd'` argument to the `fit` function. Method-specific arguments can be passed via the `inf_kwargs` argument. \n",
    "\n",
    "For the mixture model, let's set the number of particles to 1000 and use a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mixture_model:\n",
    "    svgd_approx = pm.fit(300, method='svgd', inf_kwargs=dict(n_particles=1000), \n",
    "                         obj_optimizer=pm.sgd(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_samples = mixture_trace.posterior['x'].values.ravel()\n",
    "svgd_samples = svgd_approx.sample(2000).posterior['x'].values.squeeze()\n",
    "\n",
    "x_range = np.linspace(min(np.min(nuts_samples), np.min(svgd_samples)), \n",
    "                      max(np.max(nuts_samples), np.max(svgd_samples)), 1000)\n",
    "nuts_kde = stats.gaussian_kde(nuts_samples)\n",
    "svgd_kde = stats.gaussian_kde(svgd_samples)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_range, y=nuts_kde(x_range), mode='lines', name='NUTS'))\n",
    "fig.add_trace(go.Scatter(x=x_range, y=svgd_kde(x_range), mode='lines', name='SVGD'))\n",
    "fig.update_layout(xaxis_title='x', yaxis_title='Density')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatches\n",
    "When dealing with large datasets, using minibatch training can drastically speed up and improve approximation performance. Large datasets impose a hefty cost on the computation of gradients. \n",
    "\n",
    "Minibatch gradient descent is a variation of the gradient descent algorithm that divides a large dataset into (much) smaller batches, each of which are used to calculate gradients, model error and updated model coefficients. These \"noisy\" gradients are more robust to the presence of local minima, and avoid having to ever use the entire dataset to calculate a gradient.\n",
    "\n",
    "There is a nice API in PyMC to handle these cases, which is avaliable through the `pm.Minibatch` class. The minibatch is just a highly specialized `TensorVariable`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate, let's simulate a large quantity of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Raw values\n",
    "data = np.random.rand(400_000, 100) \n",
    "# Scaled values\n",
    "data *= np.random.randint(1, 5, size=(100,))\n",
    "# Shifted values\n",
    "data += np.random.rand(100) * 2   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, let's fit a model without minibatch processing. This is just a simple model trying to recover the mean and standard deviation of a Gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    mu = pm.Flat('mu', shape=(100,))\n",
    "    sd = pm.HalfNormal('sd', shape=(100,))\n",
    "    like = pm.Normal('like', mu, sd, observed=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's create a custom special purpose callback to halt slow optimization. Here we define a callback that causes a hard stop when approximation runs too slowly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_after_10(approx, loss_history, i):\n",
    "    if (i > 0) and (i % 10) == 0:\n",
    "        raise StopIteration('I was slow, sorry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    advifit = pm.fit(callbacks=[stop_after_10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference is too slow, taking several seconds per iteration; fitting the approximation would have taken a long time!\n",
    "\n",
    "Instead, let's use minibatches. At every iteration, we will draw 500 random values. Since PyMC variables are just PyTensor variables, we can swap data in and out of the likelihood at each iteration. However, we need to provide the total size of the dataset in order for the model to be properly specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pm.Minibatch(data, batch_size=500)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    mu = pm.Normal('mu', mu=0., sigma=1.e5, shape=(100,))\n",
    "    sd = pm.HalfNormal('sd', shape=(100,))\n",
    "    likelihood = pm.Normal('likelihood', mu, sd, observed=X, total_size=data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with model:\n",
    "    advifit = pm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(advifit.hist);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minibatch inference is dramatically faster. Multidimensional minibatches may be needed for some corner cases where you do matrix factorization or model is very wide."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References: \n",
    "\n",
    "1. [Variational Inference from the ground up](https://www.civisanalytics.com/blog/variational-inference-ground/)\n",
    "2. [Automatic Differentiation Variational Inference. Kucukelbir, A., Tran D., Ranganath, R., Gelman, A., and Blei, D. M. (2016)](https://arxiv.org/abs/1603.00788)\n",
    "3. [Variational Inference: A Review for Statisticians. David M. Blei, Alp Kucukelbir, Jon D. McAuliffe (2016)](https://arxiv.org/abs/1601.00670)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
